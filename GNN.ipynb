{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv, knn_graph, global_mean_pool,radius_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = np.load(\"./Dataset_Filted/Simulation/gamma/npz\", allow_pickle=True)\n",
    "hitsE = data[\"hitsE\"]\n",
    "hitsM = data[\"hitsM\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "# Assume hitsE and hitsM are lists of arrays, each [n_hits, 3] for x, y, pe\n",
    "# labels is array of 0/1 for background/signal per event\n",
    "\n",
    "# Step 2: Build graph list\n",
    "graph_list = []\n",
    "for hE, hM, label in zip(hitsE, hitsM, labels):\n",
    "    # Combine hits from electromagnetic and muon detectors\n",
    "    if len(hE) > 0 and len(hM) > 0:\n",
    "        nodes = np.vstack([hE, hM])\n",
    "    elif len(hE) > 0:\n",
    "        nodes = hE\n",
    "    elif len(hM) > 0:\n",
    "        nodes = hM\n",
    "    else:\n",
    "        continue  # Skip empty events\n",
    "\n",
    "    # Separate position and features\n",
    "    pos = torch.tensor(nodes[:, :2], dtype=torch.float32)  # [n_nodes, 2] for x, y\n",
    "    x = torch.tensor(nodes[:, 2:], dtype=torch.float32)    # [n_nodes, 1] for pe\n",
    "\n",
    "    # Build edges using k-NN based on positions (k=5 neighbors)\n",
    "    edge_index = knn_graph(pos, k=5, loop=False)  # Undirected graph\n",
    "    edge_index = radius_graph(pos, r=100.0, loop=False)  # r 是距离阈值，单位与 x, y 相同\n",
    "    # Create Data object for graph classification\n",
    "    data_graph = Data(x=x, pos=pos, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n",
    "    graph_list.append(data_graph)\n",
    "\n",
    "# Step 3: Split into train and validation sets (80/20)\n",
    "train_graphs, val_graphs = train_test_split(graph_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create data loaders\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Define GNN model for graph classification\n",
    "class GNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=64, num_classes=2):\n",
    "        super(GNNClassifier, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features to graph-level\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, optimizer, and loss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNNClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 6: Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(val_labels, val_preds)\n",
    "    auc = roc_auc_score(val_labels, val_preds) if len(set(val_labels)) > 1 else 0.0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Acc: {acc:.4f}, Val AUC: {auc:.4f}\")\n",
    "\n",
    "# Step 7: Final evaluation on validation set (after training)\n",
    "print(\"Training complete. Final validation metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328cc7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20000 events from file ./Dataset_Filted/Simulation/gamma/1e4_1e5/train_dataset_gamma_1e4_1e5_run000.npz\n",
      "Using 20000 events from file ./Dataset_Filted/Simulation/proton/1e4_1e5/train_dataset_proton_1e4_1e5_run000.npz\n",
      "Using all events (size=21370) from file ./Dataset_Filted/Simulation/monopole/E1e9/train_dataset_monopole_E1e9.npz\n",
      "Merged 61370 events from 3 files.\n"
     ]
    }
   ],
   "source": [
    "# 扩展原始代码以实现节点类型标签、边权重（距离倒数）、多头注意力（GAT）和分层建图\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.nn import knn_graph,radius_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import ana\n",
    "# Step 1: Load the data\n",
    "# data = np.load(\"./Dataset_Filted/Simulation/gamma/1e3_1e4/train_dataset_gamma_1e3_1e4_run000.npz\", allow_pickle=True)\n",
    "# hitsE = data[\"hitsE\"]\n",
    "# hitsM = data[\"hitsM\"]\n",
    "# parID = data[\"labels\"]\n",
    "\n",
    "NpzFileList=[\"./Dataset_Filted/Simulation/gamma/1e4_1e5/train_dataset_gamma_1e4_1e5_run000.npz\",\n",
    "             \"./Dataset_Filted/Simulation/proton/1e4_1e5/train_dataset_proton_1e4_1e5_run000.npz\",\n",
    "             \"./Dataset_Filted/Simulation/monopole/E1e9/train_dataset_monopole_E1e9.npz\",\n",
    "             ]\n",
    "sample_num=(20000,20000,-1)\n",
    "\n",
    "hitsE, hitsM, parID = ana.merge_npzdataset(NpzFileList,sample_num=sample_num)\n",
    "labels = np.copy(parID)\n",
    "labels[labels == 1] = 0\n",
    "labels[labels == 14] = 0\n",
    "labels[labels == 43] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6fa72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练：\n",
      "Epoch 1/50, Loss: 0.6203, Val Acc: 0.7644, Val AUC: 0.6851\n",
      "Epoch 2/50, Loss: 0.4454, Val Acc: 0.7699, Val AUC: 0.7949\n",
      "Epoch 3/50, Loss: 0.4319, Val Acc: 0.7686, Val AUC: 0.8006\n",
      "Epoch 4/50, Loss: 0.4181, Val Acc: 0.8139, Val AUC: 0.7904\n",
      "Epoch 5/50, Loss: 0.4261, Val Acc: 0.7743, Val AUC: 0.7173\n",
      "Epoch 6/50, Loss: 0.4425, Val Acc: 0.7592, Val AUC: 0.7840\n",
      "Epoch 7/50, Loss: 0.4201, Val Acc: 0.7995, Val AUC: 0.7536\n",
      "Epoch 8/50, Loss: 0.4212, Val Acc: 0.7984, Val AUC: 0.7603\n",
      "Epoch 9/50, Loss: 0.4310, Val Acc: 0.7989, Val AUC: 0.7612\n",
      "Epoch 10/50, Loss: 0.4271, Val Acc: 0.7959, Val AUC: 0.7956\n",
      "Epoch 11/50, Loss: 0.4175, Val Acc: 0.8073, Val AUC: 0.7663\n",
      "Epoch 12/50, Loss: 0.4114, Val Acc: 0.8045, Val AUC: 0.7763\n",
      "Epoch 13/50, Loss: 0.4167, Val Acc: 0.8035, Val AUC: 0.8058\n",
      "Epoch 14/50, Loss: 0.4240, Val Acc: 0.7944, Val AUC: 0.7427\n",
      "Epoch 15/50, Loss: 0.4185, Val Acc: 0.7392, Val AUC: 0.6412\n",
      "Epoch 16/50, Loss: 0.4182, Val Acc: 0.7973, Val AUC: 0.7888\n",
      "Epoch 17/50, Loss: 0.4112, Val Acc: 0.7955, Val AUC: 0.8070\n",
      "Epoch 18/50, Loss: 0.4140, Val Acc: 0.8041, Val AUC: 0.7653\n",
      "Epoch 19/50, Loss: 0.4219, Val Acc: 0.8030, Val AUC: 0.8092\n",
      "Epoch 20/50, Loss: 0.4143, Val Acc: 0.7035, Val AUC: 0.5879\n",
      "Epoch 21/50, Loss: 0.4146, Val Acc: 0.8041, Val AUC: 0.7660\n",
      "Epoch 22/50, Loss: 0.4130, Val Acc: 0.8088, Val AUC: 0.7956\n",
      "Epoch 23/50, Loss: 0.4151, Val Acc: 0.8091, Val AUC: 0.7832\n",
      "Epoch 24/50, Loss: 0.4195, Val Acc: 0.7908, Val AUC: 0.7403\n",
      "Epoch 25/50, Loss: 0.4137, Val Acc: 0.8046, Val AUC: 0.7636\n",
      "Epoch 26/50, Loss: 0.4141, Val Acc: 0.7743, Val AUC: 0.6995\n",
      "Epoch 27/50, Loss: 0.4312, Val Acc: 0.7981, Val AUC: 0.7547\n",
      "Epoch 28/50, Loss: 0.4127, Val Acc: 0.7866, Val AUC: 0.7262\n",
      "Epoch 29/50, Loss: 0.4128, Val Acc: 0.8039, Val AUC: 0.7818\n",
      "Epoch 30/50, Loss: 0.4145, Val Acc: 0.8080, Val AUC: 0.7946\n",
      "Epoch 31/50, Loss: 0.4116, Val Acc: 0.8023, Val AUC: 0.7602\n",
      "Epoch 32/50, Loss: 0.4090, Val Acc: 0.8075, Val AUC: 0.7894\n",
      "Epoch 33/50, Loss: 0.4064, Val Acc: 0.8050, Val AUC: 0.7815\n",
      "Epoch 34/50, Loss: 0.4056, Val Acc: 0.8032, Val AUC: 0.7655\n",
      "Epoch 35/50, Loss: 0.4161, Val Acc: 0.8058, Val AUC: 0.7749\n",
      "Epoch 36/50, Loss: 0.4149, Val Acc: 0.8046, Val AUC: 0.7701\n",
      "Epoch 37/50, Loss: 0.4071, Val Acc: 0.7955, Val AUC: 0.7928\n",
      "Epoch 38/50, Loss: 0.4095, Val Acc: 0.8085, Val AUC: 0.7773\n",
      "Epoch 39/50, Loss: 0.4048, Val Acc: 0.7968, Val AUC: 0.7450\n",
      "Epoch 40/50, Loss: 0.4858, Val Acc: 0.6731, Val AUC: 0.6314\n",
      "Epoch 41/50, Loss: 0.5850, Val Acc: 0.6533, Val AUC: 0.5335\n",
      "Epoch 42/50, Loss: 0.5997, Val Acc: 0.6611, Val AUC: 0.6008\n",
      "Epoch 43/50, Loss: 0.5619, Val Acc: 0.7328, Val AUC: 0.6770\n",
      "Epoch 44/50, Loss: 0.5311, Val Acc: 0.7314, Val AUC: 0.6690\n",
      "Epoch 45/50, Loss: 0.5287, Val Acc: 0.7227, Val AUC: 0.6496\n",
      "Epoch 46/50, Loss: 0.5291, Val Acc: 0.7262, Val AUC: 0.6535\n",
      "Epoch 47/50, Loss: 0.5259, Val Acc: 0.7178, Val AUC: 0.6292\n",
      "Epoch 48/50, Loss: 0.5283, Val Acc: 0.7331, Val AUC: 0.6670\n",
      "Epoch 49/50, Loss: 0.5231, Val Acc: 0.7305, Val AUC: 0.6627\n",
      "Epoch 50/50, Loss: 0.5197, Val Acc: 0.7376, Val AUC: 0.6889\n",
      "Training complete. Final validation metrics:\n",
      "Accuracy: 0.7376, AUC: 0.6889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Build graph list with node types, edge weights, and hierarchical edges\n",
    "graph_list = []\n",
    "for hE, hM, label in zip(hitsE, hitsM, labels):\n",
    "    # Combine hits from electromagnetic and muon detectors\n",
    "    if len(hE) > 0 and len(hM) > 0:\n",
    "        nodes = np.vstack([hE, hM])\n",
    "        types = np.concatenate([np.zeros(len(hE)), np.ones(len(hM))])  # 0=electromagnetic, 1=muon\n",
    "    elif len(hE) > 0:\n",
    "        nodes = hE\n",
    "        types = np.zeros(len(hE))  # Only electromagnetic\n",
    "    elif len(hM) > 0:\n",
    "        nodes = hM\n",
    "        types = np.ones(len(hM))  # Only muon\n",
    "    else:\n",
    "        continue  # Skip empty events\n",
    "\n",
    "    # Node features: [pe, type]\n",
    "    x = torch.tensor(np.column_stack([nodes[:, 2], types]), dtype=torch.float32)  # [n_nodes, 2]\n",
    "    pos = torch.tensor(nodes[:, :2], dtype=torch.float32)  # [n_nodes, 2] for x, y\n",
    "\n",
    "    # Hierarchical graph construction\n",
    "    # (1) Intra-type edges: k-NN within electromagnetic and muon hits\n",
    "    n_e = len(hE)\n",
    "    n_m = len(hM)\n",
    "    edge_index_e = knn_graph(pos[:n_e], k=5, loop=False) if n_e > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_index_m = knn_graph(pos[n_e:], k=5, loop=False) if n_m > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    if n_m > 0:\n",
    "        edge_index_m = edge_index_m + n_e  # Offset muon node indices\n",
    "\n",
    "    # (2) Inter-type edges: Connect each electromagnetic hit to nearest muon hit\n",
    "    edge_index_inter = []\n",
    "    if n_e > 0 and n_m > 0:\n",
    "        for i in range(n_e):\n",
    "            # Compute distances from electromagnetic hit i to all muon hits\n",
    "            dists = torch.norm(pos[i:i+1] - pos[n_e:], dim=1)\n",
    "            if dists.numel() > 0:\n",
    "                j = torch.argmin(dists).item()  # Nearest muon hit\n",
    "                edge_index_inter.append([i, n_e + j])\n",
    "                edge_index_inter.append([n_e + j, i])  # Undirected\n",
    "        edge_index_inter = torch.tensor(edge_index_inter, dtype=torch.long).T\n",
    "\n",
    "    # Combine edges\n",
    "    edge_index = torch.cat([edge_index_e, edge_index_m, edge_index_inter], dim=1) if edge_index_inter.numel() > 0 else torch.cat([edge_index_e, edge_index_m], dim=1)\n",
    "\n",
    "    # Edge weights: Inverse distance\n",
    "    edge_weights = []\n",
    "    for i, j in edge_index.T:\n",
    "        dist = torch.norm(pos[i] - pos[j]).item()\n",
    "        weight = 1.0 / (dist + 1e-6)  # Avoid division by zero\n",
    "        edge_weights.append(weight)\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float32)\n",
    "\n",
    "    # Create Data object\n",
    "    data_graph = Data(x=x, pos=pos, edge_index=edge_index, edge_attr=edge_weights, y=torch.tensor([label], dtype=torch.long))\n",
    "    graph_list.append(data_graph)\n",
    "\n",
    "# Step 3: Split into train and validation sets\n",
    "train_graphs, val_graphs = train_test_split(graph_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create data loaders\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Define GNN model with GAT (multi-head attention)\n",
    "class GATClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels=2, hidden_channels=64, num_classes=2, heads=4):\n",
    "        super(GATClassifier, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True)\n",
    "        self.fc = torch.nn.Linear(hidden_channels * heads, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = global_mean_pool(x, batch)  # Graph-level representation\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, optimizer, and loss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GATClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "print(\"开始训练：\")\n",
    "# Step 6: Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(val_labels, val_preds)\n",
    "    auc = roc_auc_score(val_labels, val_preds) if len(set(val_labels)) > 1 else 0.0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Acc: {acc:.4f}, Val AUC: {auc:.4f}\")\n",
    "\n",
    "# Step 7: Final evaluation\n",
    "print(\"Training complete. Final validation metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb27e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array([0,1,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
